# http://kafka.apache.org/documentation/#consumerconfigs

# An id string to pass to the server when making requests. The purpose of this is to be able to track the source of requests beyond just ip/port by allowing a logical application name to be included in server-side request logging.
client.id=consumer_from_test_group

# brokers list
# If you are working on multi-node env, then it's better to provide more than one brokers addresses because if one goes down, consumer can connect to another one.
# I don't understand one thing ?????
# from command prompt if you want to run console consumer using below command, you need zookeeper address, you don't need broker address. But using Java client, why that is not the case?????
#   bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic testmultitopic

# Since these servers are just used for the initial connection to discover the full cluster membership (which may change dynamically), this list need not contain the full set of servers (you may want more than one, though, in case a server is down).
bootstrap.servers=localhost:9092

# In kafka, every consumer has to be a part of consumer group.
# If there are multiple consumers in one consumer group, then topic's message is delivered to one of those consumers.
# In this case, topic acts like a queue in kafka.
group.id=test

# producer sends a string message to kafka and tells kafka to use StringSerializer to convert that string to bytes
# so on the other side of kafka, consumer has to deserialize it using StringDeserializer
# you can write your own custom deserializer also
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer

# If true the consumer's offset will be periodically committed in the background.
# enable.auto.commit=true # it is the default value

# The frequency in milliseconds that the consumer offsets are auto-committed to Kafka if enable.auto.commit is set to true.
#auto.commit.interval.ms=5000 # this is the default value

# fast session timeout makes it more fun to play with failover
session.timeout.ms=10000

# The minimum amount of data the server should return for a fetch request. If insufficient data is available the request will wait for that much data to accumulate before answering the request. The default setting of 1 byte means that fetch requests are answered as soon as a single byte of data is available or the fetch request times out waiting for data to arrive. Setting this to something greater than 1 will cause the server to wait for larger amounts of data to accumulate which can improve server throughput a bit at the cost of some additional latency.
fetch.min.bytes=50000
# The maximum amount of data the server should return for a fetch request. This is not an absolute maximum, if the first message in the first non-empty partition of the fetch is larger than this value, the message will still be returned to ensure that the consumer can make progress.
#fetch.max.bytes=52428800 # this is the default value

# The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by fetch.min.bytes.
fetch.max.wait.ms=500 # this is the default value

# The maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records. If poll() is not called before expiration of this timeout, then the consumer is considered failed and the group will rebalance in order to reassign the partitions to another member.
# max.poll.interval.ms=300000 # this is the default value

# The maximum number of records returned in a single call to poll().
#max.poll.records=500 # this is the default value

# The size of the TCP receive buffer (SO_RCVBUF) to use when reading data. If the value is -1, the OS default will be used.
# default value is 65536
receive.buffer.bytes=262144

# The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted
#request.timeout.ms=305000 # this is the default value

# The amount of time to wait before attempting to retry a failed request to a given topic partition. This avoids repeatedly sending requests in a tight loop under some failure scenarios.
# retry.backoff.ms=100 # it is the default value

# The maximum amount of data per-partition the server will return.
# If the first message in the first non-empty partition of the fetch is larger than this limit, the message will still be returned to ensure that the consumer can make progress. The maximum message size accepted by the broker is defined via message.max.bytes (broker config) or max.message.bytes (topic config). See fetch.max.bytes for limiting the consumer request size
# default value is 1048576
max.partition.fetch.bytes=2097152

# Heartbeats are used to ensure that the consumer's session stays active and to facilitate rebalancing when new consumers join or leave the group. The value must be set lower than session.timeout.ms, but typically should be set no higher than 1/3 of that value. It can be adjusted even lower to control the expected time for normal rebalances.
# heartbeat.interval.ms=3000 # this is the default value

# The timeout used to detect consumer failures when using Kafka's group management facility. The consumer sends periodic heartbeats to indicate its liveness to the broker. If no heartbeats are received by the broker before the expiration of this session timeout, then the broker will remove this consumer from the group and initiate a rebalance. Note that the value must be in the allowable range as configured in the broker configuration by group.min.session.timeout.ms and group.max.session.timeout.ms
# session.timeout.ms=10000 # it is the default value

# A list of classes to use as interceptors. Implementing the ConsumerInterceptor interface allows you to intercept (and possibly mutate) records received by the consumer. By default, there are no interceptors.
# interceptor.classes

# A list of classes to use as metrics reporters. Implementing the MetricReporter interface allows plugging in classes that will be notified of new metric creation. The JmxReporter is always included to register JMX statistics.
# metric.reporters

# Whether records from internal topics (such as offsets) should be exposed to the consumer. If set to true the only way to receive records from an internal topic is subscribing to it.
# exclude.internal.topics