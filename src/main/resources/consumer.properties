# brokers list
# If you are working on multi-node env, then it's better to provide more than one brokers addresses because if one goes down, consumer can connect to another one.
# I don't understand one thing ?????
# from command prompt if you want to run console consumer using below command, you need zookeeper address, you don't need broker address. But using Java client, why that is not the case?????
#   bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic testmultitopic

bootstrap.servers=localhost:9092

# In kafka, every consumer has to be a part of consumer group.
# If there are multiple consumers in one consumer group, then topic's message is delivered to one of those consumers.
# In this case, topic acts like a queue in kafka.
group.id=test

# producer sends a string message to kafka and tells kafka to use StringSerializer to convert that string to bytes
# so on the other side of kafka, consumer has to deserialize it using StringDeserializer
# you can write your own custom deserializer also
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer


enable.auto.commit=true

# fast session timeout makes it more fun to play with failover
session.timeout.ms=10000

# These buffer sizes seem to be needed to avoid consumer switching to
# a mode where it processes one bufferful every 5 seconds with multiple
# timeouts along the way.  No idea why this happens.
fetch.min.bytes=50000
receive.buffer.bytes=262144
max.partition.fetch.bytes=2097152